#!/usr/bin/env python3
"""
üî• SAIT_01 Progressive Stress Testing Suite
===============================================
Escalating intensity tests to find system breaking points
Individual Node ‚Üí Mesh Network ‚Üí Multi-Node Scenarios
"""

import numpy as np
import time
import threading
import multiprocessing
import psutil
import gc
import sys
import warnings
warnings.filterwarnings("ignore")

class SAIT01StressTestSuite:
    def __init__(self):
        self.test_results = []
        self.failure_points = []
        self.max_intensity_reached = {}
        
    def log_result(self, test_name, intensity, status, metrics):
        """Log test result with performance metrics"""
        result = {
            'test': test_name,
            'intensity': intensity,
            'status': status,
            'metrics': metrics,
            'timestamp': time.time()
        }
        self.test_results.append(result)
        
        if status == 'FAILED':
            self.failure_points.append(result)
            
        print(f"üìä {test_name} [Intensity {intensity}]: {status}")
        for key, value in metrics.items():
            print(f"    {key}: {value}")

    def measure_system_resources(self):
        """Measure current system resource usage"""
        return {
            'cpu_percent': psutil.cpu_percent(),
            'memory_mb': psutil.Process().memory_info().rss / 1024 / 1024,
            'memory_percent': psutil.virtual_memory().percent
        }

    def stress_test_1_audio_processing_overload(self):
        """Test 1: Audio Processing Overload - Find processing limits"""
        print("\nüî• STRESS TEST 1: Audio Processing Overload")
        print("=" * 60)
        
        from hardened_spectrum_analysis import HardenedAdvancedSpectrumAnalyzer
        
        try:
            analyzer = HardenedAdvancedSpectrumAnalyzer()
        except:
            print("‚ùå Failed to initialize analyzer")
            return
        
        # Progressive intensity levels
        intensities = [
            (1, "Normal Load", 10, 16000),      # 10 samples, 1 second audio
            (2, "High Load", 50, 16000),       # 50 samples
            (3, "Extreme Load", 100, 32000),   # 100 samples, 2 second audio
            (4, "Burst Load", 200, 32000),     # 200 samples
            (5, "Memory Killer", 500, 48000),  # 500 samples, 3 second audio
            (6, "CPU Melter", 1000, 64000),    # 1000 samples, 4 second audio
            (7, "System Crusher", 2000, 80000) # 2000 samples, 5 second audio
        ]
        
        for intensity, name, sample_count, audio_length in intensities:
            print(f"\nüî• Level {intensity}: {name}")
            
            start_resources = self.measure_system_resources()
            start_time = time.time()
            
            try:
                successful_processes = 0
                failed_processes = 0
                total_processing_time = 0
                
                for i in range(sample_count):
                    # Generate realistic audio with varying complexity
                    if i % 100 == 0:
                        print(f"  Processing {i}/{sample_count}...")
                    
                    # Create increasingly complex audio patterns
                    base_signal = np.random.randn(audio_length) * 0.3
                    
                    # Add complexity based on intensity
                    if intensity >= 3:
                        # Add multiple frequency components
                        for freq in [440, 880, 1320, 1760]:
                            base_signal += 0.1 * np.sin(2 * np.pi * freq * np.linspace(0, audio_length/16000, audio_length))
                    
                    if intensity >= 5:
                        # Add noise bursts and transients
                        burst_points = np.random.randint(0, audio_length, size=10)
                        for point in burst_points:
                            if point < audio_length - 1000:
                                base_signal[point:point+1000] += np.random.randn(1000) * 2.0
                    
                    if intensity >= 6:
                        # Add chirps and frequency sweeps
                        t = np.linspace(0, audio_length/16000, audio_length)
                        chirp = np.sin(2 * np.pi * (100 + 1000 * t) * t)
                        base_signal += 0.2 * chirp
                    
                    # Process audio
                    process_start = time.time()
                    try:
                        features = analyzer.extract_spectral_features(base_signal)
                        process_time = (time.time() - process_start) * 1000
                        total_processing_time += process_time
                        
                        if process_time > 10000:  # 10 second timeout
                            print(f"    ‚ö†Ô∏è  Slow processing: {process_time:.1f}ms")
                            failed_processes += 1
                        else:
                            successful_processes += 1
                            
                    except Exception as e:
                        failed_processes += 1
                        if failed_processes <= 5:  # Only show first few errors
                            print(f"    ‚ùå Processing error: {e}")
                
                end_time = time.time()
                end_resources = self.measure_system_resources()
                
                # Calculate metrics
                total_time = end_time - start_time
                avg_processing_time = total_processing_time / sample_count if sample_count > 0 else 0
                success_rate = (successful_processes / sample_count) * 100 if sample_count > 0 else 0
                
                metrics = {
                    'total_time_sec': round(total_time, 2),
                    'avg_processing_ms': round(avg_processing_time, 2),
                    'success_rate_percent': round(success_rate, 1),
                    'successful_processes': successful_processes,
                    'failed_processes': failed_processes,
                    'cpu_usage_percent': round(end_resources['cpu_percent'] - start_resources['cpu_percent'], 1),
                    'memory_usage_mb': round(end_resources['memory_mb'] - start_resources['memory_mb'], 1),
                    'samples_per_second': round(sample_count / total_time, 1)
                }
                
                # Determine if test passed
                if success_rate < 80 or avg_processing_time > 5000:
                    status = 'FAILED'
                    self.max_intensity_reached['audio_processing'] = intensity - 1
                else:
                    status = 'PASSED'
                
                self.log_result(f"Audio Processing Level {intensity}", intensity, status, metrics)
                
                if status == 'FAILED':
                    print(f"üíÄ BREAKING POINT REACHED at Level {intensity}")
                    break
                    
            except Exception as e:
                metrics = {
                    'error': str(e),
                    'critical_failure': True
                }
                self.log_result(f"Audio Processing Level {intensity}", intensity, 'CRITICAL_FAILURE', metrics)
                print(f"üíÄ CRITICAL FAILURE at Level {intensity}: {e}")
                break
            
            # Force garbage collection between tests
            gc.collect()
            time.sleep(2)

    def stress_test_2_memory_exhaustion(self):
        """Test 2: Memory Exhaustion - Find memory limits"""
        print("\nüî• STRESS TEST 2: Memory Exhaustion Attack")
        print("=" * 60)
        
        from hardened_spectrum_analysis import HardenedAdvancedSpectrumAnalyzer
        
        try:
            analyzer = HardenedAdvancedSpectrumAnalyzer()
        except:
            print("‚ùå Failed to initialize analyzer")
            return
        
        # Progressive memory allocation levels
        intensities = [
            (1, "Small Arrays", 100, 16000),        # 100 arrays, 16K samples each
            (2, "Medium Arrays", 200, 32000),       # 200 arrays, 32K samples each  
            (3, "Large Arrays", 300, 64000),        # 300 arrays, 64K samples each
            (4, "Huge Arrays", 400, 128000),        # 400 arrays, 128K samples each
            (5, "Memory Bomb", 500, 256000),        # 500 arrays, 256K samples each
            (6, "RAM Killer", 800, 320000),         # 800 arrays, 320K samples each
            (7, "System Destroyer", 1000, 500000)   # 1000 arrays, 500K samples each
        ]
        
        allocated_arrays = []
        
        for intensity, name, array_count, array_size in intensities:
            print(f"\nüî• Level {intensity}: {name}")
            
            start_resources = self.measure_system_resources()
            start_time = time.time()
            
            try:
                successful_allocations = 0
                failed_allocations = 0
                successful_processes = 0
                
                for i in range(array_count):
                    if i % 50 == 0:
                        print(f"  Allocating array {i}/{array_count}...")
                    
                    try:
                        # Allocate large audio array
                        audio_array = np.random.randn(array_size).astype(np.float32)
                        allocated_arrays.append(audio_array)
                        successful_allocations += 1
                        
                        # Try to process every 10th array
                        if i % 10 == 0:
                            try:
                                features = analyzer.extract_spectral_features(audio_array[:16000])
                                successful_processes += 1
                            except Exception as e:
                                print(f"    ‚ùå Processing failed on array {i}: {e}")
                        
                    except MemoryError:
                        print(f"    üíÄ MEMORY EXHAUSTED at array {i}")
                        failed_allocations += 1
                        break
                    except Exception as e:
                        print(f"    ‚ùå Allocation failed: {e}")
                        failed_allocations += 1
                        if failed_allocations > 10:
                            break
                
                end_time = time.time()
                end_resources = self.measure_system_resources()
                
                # Calculate metrics
                total_time = end_time - start_time
                total_memory_mb = sum(arr.nbytes for arr in allocated_arrays) / 1024 / 1024
                
                metrics = {
                    'total_time_sec': round(total_time, 2),
                    'successful_allocations': successful_allocations,
                    'failed_allocations': failed_allocations,
                    'successful_processes': successful_processes,
                    'total_memory_allocated_mb': round(total_memory_mb, 1),
                    'system_memory_mb': round(end_resources['memory_mb'], 1),
                    'memory_percent': round(end_resources['memory_percent'], 1),
                    'arrays_in_memory': len(allocated_arrays)
                }
                
                # Determine if test passed
                if failed_allocations > 0 or end_resources['memory_percent'] > 90:
                    status = 'FAILED'
                    self.max_intensity_reached['memory_exhaustion'] = intensity - 1
                else:
                    status = 'PASSED'
                
                self.log_result(f"Memory Exhaustion Level {intensity}", intensity, status, metrics)
                
                if status == 'FAILED':
                    print(f"üíÄ MEMORY BREAKING POINT at Level {intensity}")
                    break
                    
            except Exception as e:
                metrics = {
                    'error': str(e),
                    'critical_failure': True,
                    'arrays_allocated': len(allocated_arrays)
                }
                self.log_result(f"Memory Exhaustion Level {intensity}", intensity, 'CRITICAL_FAILURE', metrics)
                print(f"üíÄ CRITICAL FAILURE at Level {intensity}: {e}")
                break
            
            time.sleep(1)
        
        # Cleanup
        print(f"\nüßπ Cleaning up {len(allocated_arrays)} allocated arrays...")
        del allocated_arrays
        gc.collect()

    def stress_test_3_concurrent_processing(self):
        """Test 3: Concurrent Processing - Find threading limits"""
        print("\nüî• STRESS TEST 3: Concurrent Processing Overload")
        print("=" * 60)
        
        # Progressive concurrency levels
        intensities = [
            (1, "Low Concurrency", 4, 10),      # 4 threads, 10 samples each
            (2, "Medium Concurrency", 8, 20),   # 8 threads, 20 samples each
            (3, "High Concurrency", 16, 30),    # 16 threads, 30 samples each
            (4, "Extreme Concurrency", 32, 40), # 32 threads, 40 samples each
            (5, "Thread Bomb", 64, 50),         # 64 threads, 50 samples each
            (6, "CPU Crusher", 128, 60),        # 128 threads, 60 samples each
            (7, "System Killer", 256, 70)       # 256 threads, 70 samples each
        ]
        
        def worker_thread(thread_id, samples_per_thread, results_queue):
            """Worker thread function"""
            try:
                from hardened_spectrum_analysis import HardenedAdvancedSpectrumAnalyzer
                analyzer = HardenedAdvancedSpectrumAnalyzer()
                
                successful = 0
                failed = 0
                
                for i in range(samples_per_thread):
                    try:
                        # Generate test audio
                        audio = np.random.randn(16000) * 0.3
                        
                        # Add some complexity
                        audio += 0.1 * np.sin(2 * np.pi * 440 * np.linspace(0, 1, 16000))
                        
                        # Process
                        features = analyzer.extract_spectral_features(audio)
                        successful += 1
                        
                    except Exception as e:
                        failed += 1
                        if failed <= 2:  # Limit error output
                            print(f"    Thread {thread_id} error: {e}")
                
                results_queue.put({
                    'thread_id': thread_id,
                    'successful': successful,
                    'failed': failed
                })
                
            except Exception as e:
                results_queue.put({
                    'thread_id': thread_id,
                    'successful': 0,
                    'failed': samples_per_thread,
                    'error': str(e)
                })
        
        for intensity, name, thread_count, samples_per_thread in intensities:
            print(f"\nüî• Level {intensity}: {name}")
            print(f"  Spawning {thread_count} threads with {samples_per_thread} samples each")
            
            start_resources = self.measure_system_resources()
            start_time = time.time()
            
            try:
                import queue
                results_queue = queue.Queue()
                threads = []
                
                # Create and start threads
                for i in range(thread_count):
                    thread = threading.Thread(
                        target=worker_thread, 
                        args=(i, samples_per_thread, results_queue)
                    )
                    threads.append(thread)
                    thread.start()
                
                # Wait for all threads to complete with timeout
                timeout_per_thread = 30  # 30 seconds per thread max
                total_timeout = timeout_per_thread * thread_count
                
                completed_threads = 0
                for thread in threads:
                    thread.join(timeout=timeout_per_thread)
                    if not thread.is_alive():
                        completed_threads += 1
                    else:
                        print(f"    ‚ö†Ô∏è  Thread timed out")
                
                # Collect results
                total_successful = 0
                total_failed = 0
                thread_errors = 0
                
                while not results_queue.empty():
                    try:
                        result = results_queue.get_nowait()
                        total_successful += result['successful']
                        total_failed += result['failed']
                        if 'error' in result:
                            thread_errors += 1
                    except queue.Empty:
                        break
                
                end_time = time.time()
                end_resources = self.measure_system_resources()
                
                # Calculate metrics
                total_time = end_time - start_time
                total_samples = thread_count * samples_per_thread
                success_rate = (total_successful / total_samples) * 100 if total_samples > 0 else 0
                
                metrics = {
                    'total_time_sec': round(total_time, 2),
                    'threads_spawned': thread_count,
                    'threads_completed': completed_threads,
                    'total_samples': total_samples,
                    'successful_processes': total_successful,
                    'failed_processes': total_failed,
                    'thread_errors': thread_errors,
                    'success_rate_percent': round(success_rate, 1),
                    'samples_per_second': round(total_successful / total_time, 1),
                    'cpu_usage_percent': round(end_resources['cpu_percent'], 1),
                    'memory_usage_mb': round(end_resources['memory_mb'] - start_resources['memory_mb'], 1)
                }
                
                # Determine if test passed
                if success_rate < 70 or completed_threads < thread_count * 0.8:
                    status = 'FAILED'
                    self.max_intensity_reached['concurrent_processing'] = intensity - 1
                else:
                    status = 'PASSED'
                
                self.log_result(f"Concurrent Processing Level {intensity}", intensity, status, metrics)
                
                if status == 'FAILED':
                    print(f"üíÄ CONCURRENCY BREAKING POINT at Level {intensity}")
                    break
                    
            except Exception as e:
                metrics = {
                    'error': str(e),
                    'critical_failure': True
                }
                self.log_result(f"Concurrent Processing Level {intensity}", intensity, 'CRITICAL_FAILURE', metrics)
                print(f"üíÄ CRITICAL FAILURE at Level {intensity}: {e}")
                break
            
            time.sleep(3)  # Recovery time between tests

    def stress_test_4_mesh_network_load(self):
        """Test 4: Mesh Network Load - Simulate network stress"""
        print("\nüî• STRESS TEST 4: Mesh Network Load")
        print("=" * 60)
        
        # Simulate mesh network load with dummy data
        intensities = [
            (1, "Small Mesh", 5, 100),          # 5 nodes, 100 messages each
            (2, "Medium Mesh", 10, 200),        # 10 nodes, 200 messages each
            (3, "Large Mesh", 20, 300),         # 20 nodes, 300 messages each
            (4, "Huge Mesh", 50, 400),          # 50 nodes, 400 messages each
            (5, "Massive Mesh", 100, 500),      # 100 nodes, 500 messages each
            (6, "Network Flood", 200, 600),     # 200 nodes, 600 messages each
            (7, "Network Apocalypse", 500, 1000) # 500 nodes, 1000 messages each
        ]
        
        for intensity, name, node_count, messages_per_node in intensities:
            print(f"\nüî• Level {intensity}: {name}")
            print(f"  Simulating {node_count} nodes with {messages_per_node} messages each")
            
            start_resources = self.measure_system_resources()
            start_time = time.time()
            
            try:
                # Simulate mesh network message processing
                total_messages = node_count * messages_per_node
                processed_messages = 0
                failed_messages = 0
                encryption_operations = 0
                routing_operations = 0
                
                for node_id in range(node_count):
                    if node_id % 20 == 0:
                        print(f"  Processing node {node_id}/{node_count}...")
                    
                    for msg_id in range(messages_per_node):
                        try:
                            # Simulate message processing load
                            
                            # 1. Encryption simulation (CPU intensive)
                            dummy_data = np.random.bytes(256)  # 256 byte message
                            encrypted_data = hash(dummy_data)  # Simulate encryption
                            encryption_operations += 1
                            
                            # 2. Routing simulation
                            destination_node = (node_id + msg_id) % node_count
                            routing_cost = abs(destination_node - node_id)
                            routing_operations += 1
                            
                            # 3. Network delay simulation
                            if intensity >= 4:
                                # Simulate network congestion
                                time.sleep(0.0001)  # 0.1ms delay
                            
                            if intensity >= 6:
                                # Simulate heavy packet loss and retransmission
                                if np.random.random() < 0.1:  # 10% packet loss
                                    time.sleep(0.001)  # 1ms retry delay
                            
                            processed_messages += 1
                            
                        except Exception as e:
                            failed_messages += 1
                            if failed_messages <= 5:
                                print(f"    ‚ùå Message processing error: {e}")
                
                end_time = time.time()
                end_resources = self.measure_system_resources()
                
                # Calculate metrics
                total_time = end_time - start_time
                throughput = processed_messages / total_time if total_time > 0 else 0
                success_rate = (processed_messages / total_messages) * 100 if total_messages > 0 else 0
                
                metrics = {
                    'total_time_sec': round(total_time, 2),
                    'simulated_nodes': node_count,
                    'total_messages': total_messages,
                    'processed_messages': processed_messages,
                    'failed_messages': failed_messages,
                    'encryption_ops': encryption_operations,
                    'routing_ops': routing_operations,
                    'success_rate_percent': round(success_rate, 1),
                    'messages_per_second': round(throughput, 1),
                    'cpu_usage_percent': round(end_resources['cpu_percent'], 1),
                    'memory_usage_mb': round(end_resources['memory_mb'] - start_resources['memory_mb'], 1)
                }
                
                # Determine if test passed
                if success_rate < 80 or throughput < 100:
                    status = 'FAILED'
                    self.max_intensity_reached['mesh_network'] = intensity - 1
                else:
                    status = 'PASSED'
                
                self.log_result(f"Mesh Network Level {intensity}", intensity, status, metrics)
                
                if status == 'FAILED':
                    print(f"üíÄ NETWORK BREAKING POINT at Level {intensity}")
                    break
                    
            except Exception as e:
                metrics = {
                    'error': str(e),
                    'critical_failure': True
                }
                self.log_result(f"Mesh Network Level {intensity}", intensity, 'CRITICAL_FAILURE', metrics)
                print(f"üíÄ CRITICAL FAILURE at Level {intensity}: {e}")
                break
            
            time.sleep(2)

    def stress_test_5_multi_node_simulation(self):
        """Test 5: Multi-Node Simulation - Full system simulation"""
        print("\nüî• STRESS TEST 5: Multi-Node System Simulation")
        print("=" * 60)
        
        # Progressive multi-node scenarios
        intensities = [
            (1, "Small Deployment", 3, 50),      # 3 nodes, 50 operations each
            (2, "Medium Deployment", 8, 100),    # 8 nodes, 100 operations each
            (3, "Large Deployment", 15, 150),    # 15 nodes, 150 operations each
            (4, "Enterprise Deployment", 25, 200), # 25 nodes, 200 operations each
            (5, "Massive Deployment", 50, 250),  # 50 nodes, 250 operations each
            (6, "Industrial Scale", 100, 300),   # 100 nodes, 300 operations each
            (7, "Defense Grid", 200, 400)        # 200 nodes, 400 operations each
        ]
        
        def simulate_node(node_id, operations_count, results_queue):
            """Simulate a complete SAIT_01 node"""
            try:
                from hardened_spectrum_analysis import HardenedAdvancedSpectrumAnalyzer
                
                # Initialize node components
                analyzer = HardenedAdvancedSpectrumAnalyzer()
                
                node_stats = {
                    'node_id': node_id,
                    'audio_processed': 0,
                    'threats_detected': 0,
                    'network_messages': 0,
                    'encryption_ops': 0,
                    'ranging_ops': 0,
                    'ota_checks': 0,
                    'errors': 0,
                    'total_time': 0
                }
                
                start_time = time.time()
                
                for op in range(operations_count):
                    try:
                        # Simulate different node operations
                        operation_type = op % 6
                        
                        if operation_type == 0:
                            # Audio processing
                            audio = np.random.randn(16000) * 0.3
                            features = analyzer.extract_spectral_features(audio)
                            node_stats['audio_processed'] += 1
                            
                            # Simulate threat detection
                            if np.random.random() < 0.1:  # 10% threat rate
                                node_stats['threats_detected'] += 1
                        
                        elif operation_type == 1:
                            # Network communication simulation
                            dummy_msg = np.random.bytes(128)
                            encrypted = hash(dummy_msg)  # Simulate encryption
                            node_stats['network_messages'] += 1
                            node_stats['encryption_ops'] += 1
                        
                        elif operation_type == 2:
                            # UWB ranging simulation
                            distance = np.random.random() * 100  # Simulate ranging
                            node_stats['ranging_ops'] += 1
                        
                        elif operation_type == 3:
                            # Mesh coordination simulation
                            coordination_data = np.random.randn(64)
                            processed = np.mean(coordination_data)
                            node_stats['network_messages'] += 1
                        
                        elif operation_type == 4:
                            # Security operations simulation
                            security_token = hash(str(node_id) + str(op))
                            node_stats['encryption_ops'] += 1
                        
                        elif operation_type == 5:
                            # OTA check simulation
                            if op % 50 == 0:  # Check every 50 operations
                                node_stats['ota_checks'] += 1
                                time.sleep(0.001)  # Simulate network delay
                        
                    except Exception as e:
                        node_stats['errors'] += 1
                        if node_stats['errors'] <= 3:
                            print(f"    Node {node_id} error: {e}")
                
                node_stats['total_time'] = time.time() - start_time
                results_queue.put(node_stats)
                
            except Exception as e:
                error_stats = {
                    'node_id': node_id,
                    'critical_error': str(e),
                    'total_time': time.time() - start_time if 'start_time' in locals() else 0
                }
                results_queue.put(error_stats)
        
        for intensity, name, node_count, operations_per_node in intensities:
            print(f"\nüî• Level {intensity}: {name}")
            print(f"  Simulating {node_count} complete SAIT_01 nodes")
            
            start_resources = self.measure_system_resources()
            start_time = time.time()
            
            try:
                import queue
                results_queue = queue.Queue()
                processes = []
                
                # Create node processes
                for node_id in range(node_count):
                    process = multiprocessing.Process(
                        target=simulate_node,
                        args=(node_id, operations_per_node, results_queue)
                    )
                    processes.append(process)
                    process.start()
                
                # Wait for all processes
                timeout = 60  # 60 second timeout per intensity level
                completed_processes = 0
                
                for process in processes:
                    process.join(timeout=timeout)
                    if not process.is_alive():
                        completed_processes += 1
                    else:
                        print(f"    ‚ö†Ô∏è  Process timed out, terminating...")
                        process.terminate()
                
                # Collect results
                node_results = []
                while not results_queue.empty():
                    try:
                        result = results_queue.get_nowait()
                        node_results.append(result)
                    except queue.Empty:
                        break
                
                end_time = time.time()
                end_resources = self.measure_system_resources()
                
                # Aggregate metrics
                total_time = end_time - start_time
                total_audio_processed = sum(r.get('audio_processed', 0) for r in node_results)
                total_threats = sum(r.get('threats_detected', 0) for r in node_results)
                total_network_msgs = sum(r.get('network_messages', 0) for r in node_results)
                total_errors = sum(r.get('errors', 0) for r in node_results)
                critical_errors = sum(1 for r in node_results if 'critical_error' in r)
                
                metrics = {
                    'total_time_sec': round(total_time, 2),
                    'nodes_simulated': node_count,
                    'nodes_completed': completed_processes,
                    'total_audio_processed': total_audio_processed,
                    'total_threats_detected': total_threats,
                    'total_network_messages': total_network_msgs,
                    'total_errors': total_errors,
                    'critical_errors': critical_errors,
                    'audio_throughput': round(total_audio_processed / total_time, 1),
                    'network_throughput': round(total_network_msgs / total_time, 1),
                    'cpu_usage_percent': round(end_resources['cpu_percent'], 1),
                    'memory_usage_mb': round(end_resources['memory_mb'] - start_resources['memory_mb'], 1)
                }
                
                # Determine if test passed
                success_rate = (completed_processes / node_count) * 100 if node_count > 0 else 0
                
                if success_rate < 80 or critical_errors > node_count * 0.1:
                    status = 'FAILED'
                    self.max_intensity_reached['multi_node'] = intensity - 1
                else:
                    status = 'PASSED'
                
                self.log_result(f"Multi-Node Level {intensity}", intensity, status, metrics)
                
                if status == 'FAILED':
                    print(f"üíÄ MULTI-NODE BREAKING POINT at Level {intensity}")
                    break
                    
            except Exception as e:
                metrics = {
                    'error': str(e),
                    'critical_failure': True
                }
                self.log_result(f"Multi-Node Level {intensity}", intensity, 'CRITICAL_FAILURE', metrics)
                print(f"üíÄ CRITICAL FAILURE at Level {intensity}: {e}")
                break
            
            time.sleep(5)  # Recovery time between levels

    def generate_final_report(self):
        """Generate comprehensive test report"""
        print("\n" + "="*80)
        print("üî• SAIT_01 PROGRESSIVE STRESS TEST - FINAL REPORT")
        print("="*80)
        
        print(f"\nüìä SUMMARY")
        print("-" * 40)
        print(f"Total tests conducted: {len(self.test_results)}")
        print(f"Tests passed: {len([r for r in self.test_results if r['status'] == 'PASSED'])}")
        print(f"Tests failed: {len([r for r in self.test_results if r['status'] == 'FAILED'])}")
        print(f"Critical failures: {len([r for r in self.test_results if r['status'] == 'CRITICAL_FAILURE'])}")
        
        print(f"\nüíÄ BREAKING POINTS DISCOVERED")
        print("-" * 40)
        for test_category, max_level in self.max_intensity_reached.items():
            print(f"  {test_category}: Level {max_level} (failed at Level {max_level + 1})")
        
        print(f"\nüö® FAILURE ANALYSIS")
        print("-" * 40)
        for failure in self.failure_points:
            print(f"  {failure['test']}: {failure['metrics'].get('error', 'Performance degradation')}")
        
        print(f"\nüéØ SYSTEM LIMITS IDENTIFIED")
        print("-" * 40)
        
        # Find the highest intensity passed for each test type
        audio_max = self.max_intensity_reached.get('audio_processing', 'Not tested')
        memory_max = self.max_intensity_reached.get('memory_exhaustion', 'Not tested')
        concurrent_max = self.max_intensity_reached.get('concurrent_processing', 'Not tested')
        mesh_max = self.max_intensity_reached.get('mesh_network', 'Not tested')
        multinode_max = self.max_intensity_reached.get('multi_node', 'Not tested')
        
        print(f"  Audio Processing Limit: Level {audio_max}")
        print(f"  Memory Exhaustion Limit: Level {memory_max}")
        print(f"  Concurrent Processing Limit: Level {concurrent_max}")
        print(f"  Mesh Network Limit: Level {mesh_max}")
        print(f"  Multi-Node System Limit: Level {multinode_max}")
        
        print(f"\nüìã RECOMMENDATIONS FOR nRF5340 DEPLOYMENT")
        print("-" * 40)
        
        if audio_max != 'Not tested' and isinstance(audio_max, int):
            if audio_max >= 5:
                print("  ‚úÖ Audio processing: Suitable for high-intensity deployment")
            elif audio_max >= 3:
                print("  ‚ö†Ô∏è  Audio processing: Moderate intensity deployment recommended")
            else:
                print("  ‚ùå Audio processing: Low intensity deployment only")
        
        if memory_max != 'Not tested' and isinstance(memory_max, int):
            if memory_max >= 5:
                print("  ‚úÖ Memory management: Suitable for large-scale deployment")
            elif memory_max >= 3:
                print("  ‚ö†Ô∏è  Memory management: Medium-scale deployment recommended")
            else:
                print("  ‚ùå Memory management: Small-scale deployment only")
        
        if concurrent_max != 'Not tested' and isinstance(concurrent_max, int):
            if concurrent_max >= 5:
                print("  ‚úÖ Concurrency: Excellent multi-threading capability")
            elif concurrent_max >= 3:
                print("  ‚ö†Ô∏è  Concurrency: Moderate multi-threading capability")
            else:
                print("  ‚ùå Concurrency: Limited multi-threading capability")
        
        # Overall assessment
        overall_scores = [v for v in self.max_intensity_reached.values() if isinstance(v, int)]
        if overall_scores:
            avg_score = sum(overall_scores) / len(overall_scores)
            print(f"\nüèÜ OVERALL SYSTEM ASSESSMENT")
            print("-" * 40)
            if avg_score >= 5:
                print("  üü¢ EXCELLENT: System ready for high-intensity defense deployment")
            elif avg_score >= 3:
                print("  üü° GOOD: System ready for moderate-intensity deployment")
            elif avg_score >= 2:
                print("  üü† FAIR: System ready for light deployment with monitoring")
            else:
                print("  üî¥ POOR: System requires optimization before deployment")
        
        print(f"\nüíæ Detailed test data available in self.test_results")
        print("="*80)

    def run_all_stress_tests(self):
        """Run the complete progressive stress test suite"""
        print("üî•üî•üî• SAIT_01 PROGRESSIVE STRESS TEST SUITE üî•üî•üî•")
        print("=" * 80)
        print("üéØ Objective: Find system breaking points through escalating stress")
        print("‚ö†Ô∏è  WARNING: This test will push the system to its limits")
        print("=" * 80)
        
        start_time = time.time()
        
        try:
            # Test 1: Audio Processing Overload
            self.stress_test_1_audio_processing_overload()
            
            # Test 2: Memory Exhaustion
            self.stress_test_2_memory_exhaustion()
            
            # Test 3: Concurrent Processing
            self.stress_test_3_concurrent_processing()
            
            # Test 4: Mesh Network Load
            self.stress_test_4_mesh_network_load()
            
            # Test 5: Multi-Node Simulation
            self.stress_test_5_multi_node_simulation()
            
        except KeyboardInterrupt:
            print("\nüõë Stress testing interrupted by user")
        except Exception as e:
            print(f"\nüíÄ Critical error during stress testing: {e}")
        
        total_time = time.time() - start_time
        print(f"\n‚è±Ô∏è  Total testing time: {total_time:.1f} seconds")
        
        # Generate final report
        self.generate_final_report()

if __name__ == "__main__":
    # Create and run stress test suite
    stress_tester = SAIT01StressTestSuite()
    stress_tester.run_all_stress_tests()