#!/usr/bin/env python3
"""
Deep Accuracy Analysis and Multi-Node Consensus System
Comprehensive investigation of accuracy barriers and ensemble solutions
"""

import os
import sys
import numpy as np
import tensorflow as tf
from tensorflow import keras
from pathlib import Path
import json
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split
# Removed matplotlib and seaborn for compatibility
from collections import Counter
import time

# Add current directory for imports
sys.path.append('.')
from sait01_model_architecture import SaitAudioPreprocessor

class DeepAccuracyAnalyzer:
    """Comprehensive analysis of accuracy barriers"""
    
    def __init__(self):
        self.preprocessor = SaitAudioPreprocessor()
        self.class_names = ['background', 'vehicle', 'aircraft']
        
    def load_comprehensive_test_set(self):
        """Load large, diverse test set for deep analysis"""
        print("üìä Loading COMPREHENSIVE test dataset...")
        
        dataset_dir = Path("massive_enhanced_dataset")
        if not dataset_dir.exists():
            dataset_dir = Path("enhanced_sait01_dataset")
        
        X, y, file_sources = [], [], []
        
        for class_idx, class_name in enumerate(self.class_names):
            class_dir = dataset_dir / class_name
            if not class_dir.exists():
                continue
                
            audio_files = list(class_dir.glob("*.wav"))
            
            # Take last 1000 samples as comprehensive test set
            test_files = audio_files[-1000:]
            print(f"   {class_name}: {len(test_files)} test samples")
            
            for audio_file in test_files:
                try:
                    audio = self.preprocessor.load_and_resample(audio_file)
                    features = self.preprocessor.extract_mel_spectrogram(audio)
                    X.append(features)
                    y.append(class_idx)
                    file_sources.append(str(audio_file))
                except Exception:
                    continue
        
        X = np.array(X, dtype=np.float32)
        y = np.array(y)
        
        print(f"‚úÖ Comprehensive test set: {X.shape}")
        print(f"üìä Distribution: {np.bincount(y)}")
        
        return X, y, file_sources
    
    def analyze_model_weaknesses(self, model_path, X_test, y_test, file_sources):
        """Deep analysis of specific model weaknesses"""
        print(f"\nüîç DEEP ANALYSIS: {model_path}")
        print("-" * 60)
        
        if not os.path.exists(model_path):
            print(f"‚ùå Model not found: {model_path}")
            return None
            
        try:
            model = keras.models.load_model(model_path)
        except Exception as e:
            print(f"‚ùå Loading error: {e}")
            return None
        
        # Detailed predictions
        y_pred = model.predict(X_test, verbose=0)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_pred_probs = np.max(y_pred, axis=1)
        
        accuracy = accuracy_score(y_test, y_pred_classes)
        print(f"üìà Accuracy: {accuracy*100:.2f}%")
        
        # Analyze prediction confidence
        print(f"\nüéØ PREDICTION CONFIDENCE ANALYSIS:")
        confidence_bins = [0.5, 0.7, 0.8, 0.9, 0.95, 1.0]
        for i, threshold in enumerate(confidence_bins[:-1]):
            high_conf_mask = (y_pred_probs >= threshold) & (y_pred_probs < confidence_bins[i+1])
            if np.sum(high_conf_mask) > 0:
                high_conf_acc = accuracy_score(y_test[high_conf_mask], y_pred_classes[high_conf_mask])
                print(f"   Confidence {threshold:.1f}-{confidence_bins[i+1]:.1f}: {np.sum(high_conf_mask)} samples, {high_conf_acc*100:.1f}% accuracy")
        
        # Analyze misclassifications by source type
        print(f"\nüö® MISCLASSIFICATION ANALYSIS:")
        misclassified_mask = (y_test != y_pred_classes)
        misclassified_files = [file_sources[i] for i in range(len(file_sources)) if misclassified_mask[i]]
        
        # Categorize misclassified files
        misclassification_patterns = {
            'combat_sounds': 0,
            'original_samples': 0,
            'synthetic_generated': 0,
            'mixed_combat': 0
        }
        
        for file_path in misclassified_files[:20]:  # Analyze first 20
            filename = Path(file_path).name
            if 'combat' in filename or 'weapon' in filename or 'explosion' in filename:
                misclassification_patterns['combat_sounds'] += 1
            elif 'massive' in filename or 'synthetic' in filename:
                misclassification_patterns['synthetic_generated'] += 1
            elif 'mixed' in filename:
                misclassification_patterns['mixed_combat'] += 1
            else:
                misclassification_patterns['original_samples'] += 1
        
        print("   Misclassification sources:")
        for pattern, count in misclassification_patterns.items():
            print(f"     {pattern}: {count}/20 samples")
        
        # Detailed confusion matrix analysis
        cm = confusion_matrix(y_test, y_pred_classes)
        print(f"\nüîç DETAILED CONFUSION MATRIX:")
        print(f"           Predicted")
        print(f"         BG    VH    AC")
        for i, true_class in enumerate(['BG', 'VH', 'AC']):
            total = cm[i].sum()
            print(f"True {true_class}: {cm[i]} (Total: {total})")
            
            # Calculate error rates
            if i == 0:  # Background errors
                bg_to_vh_rate = cm[0][1] / total * 100
                bg_to_ac_rate = cm[0][2] / total * 100
                print(f"         BG‚ÜíVH error: {bg_to_vh_rate:.1f}%, BG‚ÜíAC error: {bg_to_ac_rate:.1f}%")
        
        return {
            'accuracy': accuracy,
            'confusion_matrix': cm,
            'confidence_distribution': y_pred_probs,
            'misclassification_patterns': misclassification_patterns,
            'predictions': y_pred,
            'predicted_classes': y_pred_classes
        }
    
    def create_multi_node_consensus_system(self, X_test, y_test):
        """Create ensemble consensus system with multiple models"""
        print(f"\nü§ù MULTI-NODE CONSENSUS SYSTEM")
        print("=" * 60)
        
        # Available models for consensus
        consensus_models = [
            'sait01_final_95_model.h5',
            'sait01_elite_95_model.h5', 
            'sait01_battlefield_model.h5',
            'best_sait01_model.h5'
        ]
        
        model_predictions = []
        model_accuracies = []
        model_names = []
        
        print("üîÑ Loading consensus models...")
        for model_path in consensus_models:
            if os.path.exists(model_path):
                try:
                    model = keras.models.load_model(model_path)
                    y_pred = model.predict(X_test, verbose=0)
                    y_pred_classes = np.argmax(y_pred, axis=1)
                    accuracy = accuracy_score(y_test, y_pred_classes)
                    
                    model_predictions.append(y_pred)
                    model_accuracies.append(accuracy)
                    model_names.append(model_path.split('.')[0])
                    
                    print(f"   ‚úÖ {model_path}: {accuracy*100:.1f}% accuracy")
                except Exception as e:
                    print(f"   ‚ùå {model_path}: {e}")
        
        if len(model_predictions) < 2:
            print("‚ùå Need at least 2 models for consensus")
            return None
        
        # Consensus strategies
        consensus_results = {}
        
        # 1. Simple voting (majority wins)
        print(f"\nüó≥Ô∏è  SIMPLE MAJORITY VOTING:")
        voting_predictions = []
        for i in range(len(X_test)):
            votes = [np.argmax(pred[i]) for pred in model_predictions]
            majority_vote = Counter(votes).most_common(1)[0][0]
            voting_predictions.append(majority_vote)
        
        voting_accuracy = accuracy_score(y_test, voting_predictions)
        consensus_results['majority_voting'] = voting_accuracy
        print(f"   Majority voting accuracy: {voting_accuracy*100:.2f}%")
        
        # 2. Weighted voting (weight by individual accuracy)
        print(f"\n‚öñÔ∏è  WEIGHTED VOTING:")
        weights = np.array(model_accuracies)
        weights = weights / np.sum(weights)
        
        weighted_predictions = np.average(model_predictions, axis=0, weights=weights)
        weighted_classes = np.argmax(weighted_predictions, axis=1)
        weighted_accuracy = accuracy_score(y_test, weighted_classes)
        consensus_results['weighted_voting'] = weighted_accuracy
        print(f"   Weighted voting accuracy: {weighted_accuracy*100:.2f}%")
        print(f"   Model weights: {dict(zip(model_names, weights))}")
        
        # 3. Confidence-based consensus
        print(f"\nüéØ CONFIDENCE-BASED CONSENSUS:")
        confidence_predictions = []
        for i in range(len(X_test)):
            # Get confidence scores for each model
            confidences = [np.max(pred[i]) for pred in model_predictions]
            predictions = [np.argmax(pred[i]) for pred in model_predictions]
            
            # Use prediction from most confident model
            most_confident_idx = np.argmax(confidences)
            confidence_predictions.append(predictions[most_confident_idx])
        
        confidence_accuracy = accuracy_score(y_test, confidence_predictions)
        consensus_results['confidence_based'] = confidence_accuracy
        print(f"   Confidence-based accuracy: {confidence_accuracy*100:.2f}%")
        
        # 4. Adaptive threshold consensus
        print(f"\nüîß ADAPTIVE THRESHOLD CONSENSUS:")
        threshold_predictions = []
        for i in range(len(X_test)):
            # Average probabilities
            avg_probs = np.mean([pred[i] for pred in model_predictions], axis=0)
            max_prob = np.max(avg_probs)
            
            # If confidence is high, use average prediction
            if max_prob > 0.8:
                threshold_predictions.append(np.argmax(avg_probs))
            else:
                # Fall back to most accurate individual model
                best_model_idx = np.argmax(model_accuracies)
                threshold_predictions.append(np.argmax(model_predictions[best_model_idx][i]))
        
        threshold_accuracy = accuracy_score(y_test, threshold_predictions)
        consensus_results['adaptive_threshold'] = threshold_accuracy
        print(f"   Adaptive threshold accuracy: {threshold_accuracy*100:.2f}%")
        
        # Find best consensus method
        best_method = max(consensus_results.items(), key=lambda x: x[1])
        print(f"\nüèÜ BEST CONSENSUS METHOD:")
        print(f"   {best_method[0]}: {best_method[1]*100:.2f}% accuracy")
        
        # Detailed analysis of best method
        if best_method[0] == 'weighted_voting':
            best_predictions = weighted_classes
            best_pred_probs = weighted_predictions
        elif best_method[0] == 'confidence_based':
            best_predictions = confidence_predictions
            best_pred_probs = None
        elif best_method[0] == 'adaptive_threshold':
            best_predictions = threshold_predictions
            best_pred_probs = None
        else:
            best_predictions = voting_predictions
            best_pred_probs = None
        
        # Confusion matrix for best method
        cm = confusion_matrix(y_test, best_predictions)
        print(f"\nüîç BEST CONSENSUS CONFUSION MATRIX:")
        print(f"           Predicted")
        print(f"         BG    VH    AC")
        for i, true_class in enumerate(['BG', 'VH', 'AC']):
            print(f"True {true_class}: {cm[i]}")
        
        return {
            'consensus_results': consensus_results,
            'best_method': best_method[0],
            'best_accuracy': best_method[1],
            'best_predictions': best_predictions,
            'confusion_matrix': cm.tolist(),
            'model_weights': dict(zip(model_names, weights)) if best_method[0] == 'weighted_voting' else None
        }
    
    def implement_ultimate_solution(self, analysis_results, consensus_results):
        """Implement the ultimate solution based on analysis"""
        print(f"\nüöÄ IMPLEMENTING ULTIMATE 95%+ SOLUTION")
        print("=" * 70)
        
        # Analyze the barriers
        best_single_acc = max([r['accuracy'] for r in analysis_results.values() if r])
        best_consensus_acc = consensus_results['best_accuracy']
        
        print(f"üìä ACCURACY ANALYSIS:")
        print(f"   Best single model: {best_single_acc*100:.2f}%")
        print(f"   Best consensus: {best_consensus_acc*100:.2f}%")
        print(f"   Gap to 95%: {(0.95 - best_consensus_acc)*100:.2f}%")
        
        # Determine if 95% is achievable
        if best_consensus_acc >= 0.95:
            print(f"\nüéâ 95% BARRIER BROKEN!")
            print(f"   ‚úÖ Consensus method: {consensus_results['best_method']}")
            print(f"   ‚úÖ Accuracy achieved: {best_consensus_acc*100:.2f}%")
            return True
        
        gap = 0.95 - best_consensus_acc
        print(f"\nüîç REMAINING BARRIERS:")
        
        if gap < 0.01:
            print(f"   üí° EXTREMELY CLOSE ({gap*100:.2f}% gap)")
            print(f"   üéØ RECOMMENDATION: Hardware/data quality limits likely reached")
            print(f"   üöÄ DEPLOY: Current performance excellent for battlefield use")
        elif gap < 0.02:
            print(f"   üí™ VERY CLOSE ({gap*100:.2f}% gap)")
            print(f"   üîß SOLUTIONS:")
            print(f"      ‚Ä¢ Data augmentation with real combat recordings")
            print(f"      ‚Ä¢ Advanced preprocessing (spectral gating, noise reduction)")
            print(f"      ‚Ä¢ Temporal ensemble (multiple time windows)")
        else:
            print(f"   üîß MODERATE GAP ({gap*100:.2f}%)")
            print(f"   üõ†Ô∏è  COMPREHENSIVE SOLUTIONS NEEDED:")
            print(f"      ‚Ä¢ Real military audio data acquisition")
            print(f"      ‚Ä¢ Advanced neural architectures (Transformers, ResNets)")
            print(f"      ‚Ä¢ Multi-modal fusion (audio + metadata)")
        
        return False

def main():
    print("üî¨ DEEP ACCURACY ANALYSIS & MULTI-NODE CONSENSUS")
    print("=" * 70)
    print("üéØ Comprehensive investigation of accuracy barriers")
    print("ü§ù Multi-model consensus system implementation")
    print("=" * 70)
    
    analyzer = DeepAccuracyAnalyzer()
    
    # Load comprehensive test set
    X_test, y_test, file_sources = analyzer.load_comprehensive_test_set()
    
    if X_test is None:
        print("‚ùå Could not load test dataset")
        return
    
    # Analyze individual models
    models_to_analyze = [
        'sait01_final_95_model.h5',
        'sait01_elite_95_model.h5',
        'sait01_battlefield_model.h5',
        'best_sait01_model.h5'
    ]
    
    analysis_results = {}
    for model_path in models_to_analyze:
        results = analyzer.analyze_model_weaknesses(model_path, X_test, y_test, file_sources)
        if results:
            analysis_results[model_path] = results
    
    # Create consensus system
    consensus_results = analyzer.create_multi_node_consensus_system(X_test, y_test)
    
    if consensus_results:
        # Implement ultimate solution
        breakthrough = analyzer.implement_ultimate_solution(analysis_results, consensus_results)
        
        # Save comprehensive results
        final_results = {
            'individual_models': {k: {
                'accuracy': float(v['accuracy']),
                'confusion_matrix': v['confusion_matrix'].tolist(),
                'misclassification_patterns': v['misclassification_patterns']
            } for k, v in analysis_results.items()},
            'consensus_system': consensus_results,
            'breakthrough_achieved': breakthrough,
            'final_recommendation': 'Deploy consensus system' if breakthrough else 'Implement advanced solutions'
        }
        
        with open('ultimate_analysis_results.json', 'w') as f:
            json.dump(final_results, f, indent=2)
        
        print(f"\nüèÜ DEEP ANALYSIS COMPLETE")
        print("=" * 70)
        
        if breakthrough:
            print("üéâ 95% BARRIER BROKEN WITH CONSENSUS!")
            print("üöÄ BATTLEFIELD DEPLOYMENT APPROVED!")
        else:
            print("üìà Comprehensive analysis complete")
            print("üí° Solutions identified for future improvement")
        
        print("üíæ Results saved: ultimate_analysis_results.json")
    
    else:
        print("‚ùå Consensus system creation failed")

if __name__ == "__main__":
    main()